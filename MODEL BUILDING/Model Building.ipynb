{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! unzip Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8z51ag8fkUn",
        "outputId": "3b34fd36-1889-4c9f-be9e-c430af8d2532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Dataset.zip\n",
            "   creating: Dataset/\n",
            "   creating: Dataset/Test set/\n",
            "   creating: Dataset/Test set/Cyclone/\n",
            "  inflating: Dataset/Test set/Cyclone/867.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/868.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/869.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/870.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/871.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/872.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/873.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/874.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/875.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/876.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/877.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/878.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/879.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/880.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/881.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/882.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/883.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/884.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/885.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/886.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/887.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/888.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/889.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/890.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/891.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/892.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/893.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/894.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/895.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/896.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/897.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/898.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/899.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/900.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/901.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/902.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/903.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/904.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/905.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/906.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/907.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/908.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/909.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/910.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/911.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/912.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/913.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/914.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/915.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/916.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/917.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/918.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/919.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/920.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/921.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/922.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/923.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/924.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/925.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/926.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/927.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/928.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/929.jpg  \n",
            "  inflating: Dataset/Test set/Cyclone/930.jpg  \n",
            "   creating: Dataset/Test set/Earthquake/\n",
            "  inflating: Dataset/Test set/Earthquake/1321.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1322.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1323.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1324.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1325.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1326.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1327.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1328.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1329.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1330.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1331.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1332.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1333.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1334.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1335.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1336.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1337.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1338.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1339.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1340.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1341.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1342.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1343.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1344.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1345.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1346.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1347.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1348.jpg  \n",
            "  inflating: Dataset/Test set/Earthquake/1349.jpg  \n",
            "   creating: Dataset/Test set/Flood/\n",
            "  inflating: Dataset/Test set/Flood/1000.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1001.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1002.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1003.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1004.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1005.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1006.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1007.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1008.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1009.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1010.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1011.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1012.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1013.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1014.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1015.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1016.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1017.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1018.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1019.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1020.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1021.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1022.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1023.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1024.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1025.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1026.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1027.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1028.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1029.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1030.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1031.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1032.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1033.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1034.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1035.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1036.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1037.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1038.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1039.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1040.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1041.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1042.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1043.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1044.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1045.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1046.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1047.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1048.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1049.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1050.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1051.jpg  \n",
            "  inflating: Dataset/Test set/Flood/1062.jpg  \n",
            "  inflating: Dataset/Test set/Flood/992.jpg  \n",
            "  inflating: Dataset/Test set/Flood/993.jpg  \n",
            "  inflating: Dataset/Test set/Flood/994.jpg  \n",
            "  inflating: Dataset/Test set/Flood/995.jpg  \n",
            "  inflating: Dataset/Test set/Flood/996.jpg  \n",
            "  inflating: Dataset/Test set/Flood/997.jpg  \n",
            "  inflating: Dataset/Test set/Flood/998.jpg  \n",
            "  inflating: Dataset/Test set/Flood/999.jpg  \n",
            " extracting: Dataset/Test set/New Text Document.txt  \n",
            "   creating: Dataset/Test set/Wildfires/\n",
            "  inflating: Dataset/Test set/Wildfires/1035.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1036.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1037.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1038.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1039.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1040.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1041.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1042.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1043.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1044.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1045.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1046.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1047.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1048.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1049.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1050.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1051.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1052.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1053.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1054.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1055.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1056.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1057.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1058.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1059.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1060.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1061.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1062.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1063.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1064.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1065.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1066.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1067.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1068.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1069.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1070.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1071.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1072.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1073.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1074.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1075.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1076.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1077.jpg  \n",
            "  inflating: Dataset/Test set/Wildfires/1078.jpg  \n",
            "   creating: Dataset/Train set/\n",
            "   creating: Dataset/Train set/Cyclone/\n",
            "  inflating: Dataset/Train set/Cyclone/867.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/868.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/869.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/870.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/871.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/872.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/873.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/874.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/875.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/876.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/877.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/878.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/879.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/880.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/881.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/882.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/883.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/884.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/885.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/886.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/887.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/888.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/889.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/890.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/891.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/892.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/893.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/894.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/895.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/896.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/897.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/898.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/899.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/900.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/901.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/902.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/903.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/904.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/905.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/906.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/907.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/908.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/909.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/910.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/911.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/912.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/913.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/914.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/915.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/916.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/917.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/918.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/919.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/920.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/921.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/922.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/923.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/924.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/925.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/926.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/927.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/928.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/929.jpg  \n",
            "  inflating: Dataset/Train set/Cyclone/930.jpg  \n",
            "   creating: Dataset/Train set/Earthquake/\n",
            "  inflating: Dataset/Train set/Earthquake/1321.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1322.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1323.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1324.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1325.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1326.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1327.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1328.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1329.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1330.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1331.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1332.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1333.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1334.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1335.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1336.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1337.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1338.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1339.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1340.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1341.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1342.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1343.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1344.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1345.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1346.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1347.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1348.jpg  \n",
            "  inflating: Dataset/Train set/Earthquake/1349.jpg  \n",
            "   creating: Dataset/Train set/Flood/\n",
            "  inflating: Dataset/Train set/Flood/1000.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1001.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1002.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1003.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1004.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1005.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1006.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1007.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1008.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1009.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1010.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1011.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1012.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1013.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1014.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1015.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1016.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1017.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1018.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1019.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1020.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1021.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1022.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1023.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1024.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1025.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1026.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1027.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1028.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1029.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1030.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1031.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1032.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1033.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1034.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1035.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1036.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1037.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1038.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1039.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1040.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1041.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1042.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1043.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1044.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1045.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1046.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1047.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1048.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1049.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1050.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1051.jpg  \n",
            "  inflating: Dataset/Train set/Flood/1062.jpg  \n",
            "  inflating: Dataset/Train set/Flood/992.jpg  \n",
            "  inflating: Dataset/Train set/Flood/993.jpg  \n",
            "  inflating: Dataset/Train set/Flood/994.jpg  \n",
            "  inflating: Dataset/Train set/Flood/995.jpg  \n",
            "  inflating: Dataset/Train set/Flood/996.jpg  \n",
            "  inflating: Dataset/Train set/Flood/997.jpg  \n",
            "  inflating: Dataset/Train set/Flood/998.jpg  \n",
            "  inflating: Dataset/Train set/Flood/999.jpg  \n",
            " extracting: Dataset/Train set/New Text Document.txt  \n",
            "   creating: Dataset/Train set/Wildfires/\n",
            "  inflating: Dataset/Train set/Wildfires/1035.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1036.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1037.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1038.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1039.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1040.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1041.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1042.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1043.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1044.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1045.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1046.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1047.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1048.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1049.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1050.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1051.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1052.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1053.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1054.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1055.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1056.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1057.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1058.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1059.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1060.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1061.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1062.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1063.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1064.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1065.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1066.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1067.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1068.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1069.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1070.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1071.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1072.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1073.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1074.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1075.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1076.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1077.jpg  \n",
            "  inflating: Dataset/Train set/Wildfires/1078.jpg  \n",
            " extracting: Dataset/txt..txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing image data generator library"
      ],
      "metadata": {
        "id": "tOGN2LvhJhA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "thiINJwngjd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Data Augmentation**"
      ],
      "metadata": {
        "id": "yFrEWLy2ECgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuring image Data Generator Class\n",
        "\n",
        "#Image Augmentation for training data\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True,shear_range=0.2)"
      ],
      "metadata": {
        "id": "fJDLjlHChU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image Data Augmentation for testing data\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "TfC667SGhW8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply ImageDataGenerator Functionality To Trainset And Testset** "
      ],
      "metadata": {
        "id": "v3qPfrs0EbZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing data augmentation to train data\n",
        "\n",
        "x_train=train_datagen.flow_from_directory(r\"/content/drive/MyDrive/IBM_Dataset/Dataset/Train set\",target_size=(64,64),\n",
        "                                                            batch_size=5,color_mode='rgb',class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amBNAO6eiPNF",
        "outputId": "3191531d-e8de-44d5-c827-4eeee0ed969c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 198 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#performing data augmentation to test data\n",
        "\n",
        "x_test=train_datagen.flow_from_directory(r\"/content/drive/MyDrive/IBM_Dataset/Dataset/Test set\",target_size=(64,64),\n",
        "                                                            batch_size=5,color_mode='rgb',class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdJKjlEsidAh",
        "outputId": "cf7e09d9-c098-4cb9-b211-5150710af127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 198 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing neccessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten"
      ],
      "metadata": {
        "id": "GmL2Q-EejCbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialising the model and adding CNN layers\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "# First convolution layer and pooling\n",
        "model.add(Conv2D(32,(3,3),activation=\"relu\",input_shape=(64,64,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Second convolution layer and pooling\n",
        "model.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Flattening the layers\n",
        "model.add(Flatten())\n",
        "\n",
        "#Adding Dense Layers\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=4,activation='softmax'))\n",
        "model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer='adam')"
      ],
      "metadata": {
        "id": "xRXOiMTsjCx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of our model\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4zJ1aicjEAG",
        "outputId": "9f1ba6d7-04bc-4273-c0aa-ea491d9bc165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,604\n",
            "Trainable params: 813,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "\n",
        "model.fit_generator(generator=x_train,epochs=20,steps_per_epoch=len(x_train),validation_data=x_test,validation_steps=len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QwpfUGqjFl0",
        "outputId": "c5f5df66-8054-42db-f442-ac970c31eeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - 17s 415ms/step - loss: 1.3182 - accuracy: 0.4242 - val_loss: 1.1419 - val_accuracy: 0.6566\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 19s 474ms/step - loss: 1.1103 - accuracy: 0.5859 - val_loss: 0.8213 - val_accuracy: 0.6717\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 16s 405ms/step - loss: 0.7932 - accuracy: 0.7071 - val_loss: 0.5939 - val_accuracy: 0.7677\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.7737 - accuracy: 0.7273 - val_loss: 0.6538 - val_accuracy: 0.7576\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 16s 412ms/step - loss: 0.5688 - accuracy: 0.7879 - val_loss: 0.5207 - val_accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 16s 411ms/step - loss: 0.5855 - accuracy: 0.8081 - val_loss: 0.5104 - val_accuracy: 0.7980\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 16s 403ms/step - loss: 0.5436 - accuracy: 0.7929 - val_loss: 0.4179 - val_accuracy: 0.8586\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - 16s 389ms/step - loss: 0.4749 - accuracy: 0.8283 - val_loss: 0.4662 - val_accuracy: 0.8131\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - 16s 394ms/step - loss: 0.5987 - accuracy: 0.7879 - val_loss: 0.5838 - val_accuracy: 0.7576\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - 16s 413ms/step - loss: 0.4526 - accuracy: 0.8586 - val_loss: 0.3380 - val_accuracy: 0.9091\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - 17s 444ms/step - loss: 0.5027 - accuracy: 0.8333 - val_loss: 0.5417 - val_accuracy: 0.7778\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.3903 - accuracy: 0.8889 - val_loss: 0.3495 - val_accuracy: 0.8535\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - 16s 410ms/step - loss: 0.3818 - accuracy: 0.8182 - val_loss: 0.8336 - val_accuracy: 0.6717\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - 16s 407ms/step - loss: 0.4713 - accuracy: 0.7879 - val_loss: 0.2625 - val_accuracy: 0.8990\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - 15s 381ms/step - loss: 0.3389 - accuracy: 0.8687 - val_loss: 0.4725 - val_accuracy: 0.8485\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - 16s 404ms/step - loss: 0.2914 - accuracy: 0.8838 - val_loss: 0.1935 - val_accuracy: 0.9495\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - 16s 397ms/step - loss: 0.2296 - accuracy: 0.9242 - val_loss: 0.2188 - val_accuracy: 0.9293\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - 16s 408ms/step - loss: 0.2523 - accuracy: 0.8889 - val_loss: 0.1449 - val_accuracy: 0.9596\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - 15s 390ms/step - loss: 0.2315 - accuracy: 0.9141 - val_loss: 0.1097 - val_accuracy: 0.9697\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - 16s 399ms/step - loss: 0.1939 - accuracy: 0.9141 - val_loss: 0.1126 - val_accuracy: 0.9747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac875b6ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "\n",
        "model.save('disaster.h5')\n",
        "model_json=model.to_json()\n",
        "with open(\"model-bw.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "metadata": {
        "id": "hPitQE5_jIj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "model=load_model('disaster.h5')"
      ],
      "metadata": {
        "id": "qqZyNCU2jr1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH3UHHfcjt2F",
        "outputId": "2b7b1691-2f6a-4465-fc40-7bfb2940fb86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfires': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taking image as input\n",
        "\n",
        "img=image.load_img(r\"/content/drive/MyDrive/IBM_Dataset/Dataset/Test set/Earthquake/1321.jpg\",target_size=(64,64))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
        "y=np.argmax(model.predict(x),axis=1)\n",
        "print(index[int(y)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqqiepAbjxdV",
        "outputId": "1ca2cb29-50c2-4377-cc71-c4c84ae67584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 111ms/step\n",
            "Earthquake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taking image as input\n",
        "\n",
        "img=image.load_img(r\"/content/drive/MyDrive/IBM_Dataset/Dataset/Test set/Cyclone/882.jpg\",target_size=(64,64))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
        "y=np.argmax(model.predict(x),axis=1)\n",
        "print(index[int(y)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo--szftjypM",
        "outputId": "38da83e9-976c-473f-8d62-510e40f5b91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Cyclone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sybQ8wQkZye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}